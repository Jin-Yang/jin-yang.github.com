---
title: 贝叶斯简介
layout: post
comments: true
language: chinese
usemath: true
category: [linux,misc]
keywords: bayes' theorem
description: 贝叶斯定理 (Bayes' Theorem) 是英国数学家 托马斯·贝叶斯 (Thomas Bayes) 在 1763 年发表的一篇论文中首次提出；而贝叶斯推断 (Bayesian Inference) 是贝叶斯定理的一种应用，是一种统计学方法，用来估计统计量的某些性质。 这里简单介绍其基本概念。
---

贝叶斯定理 (Bayes' Theorem) 是英国数学家 托马斯·贝叶斯 (Thomas Bayes) 在 1763 年发表的一篇论文中首次提出；而贝叶斯推断 (Bayesian Inference) 是贝叶斯定理的一种应用，是一种统计学方法，用来估计统计量的某些性质。

这里简单介绍其基本概念。

<!-- more -->

## 简介

在统计学界一直有两种观点：A) 频率学派；B) 贝叶斯学派。

贝叶斯推断与统计学的推断方法不同，是建立在主观判断的基础上，也就是说，可以不需要客观证据，先估计一个值，然后根据实际结果不断修正。正是因为它的主观性太强，曾经遭到许多统计学家的诟病，很长时间内无法广泛应用。

在计算机获得广泛发展后，人们也逐渐意识到，许多统计量是无法事先进行客观判断的，而利用互联网中的大型数据集，可以不断更新完善模型，从而为应用贝叶斯推断创造了条件。

贝叶斯学派的思想是用数据来更新特定假设的概率。

## 贝叶斯定理

贝叶斯定理实际上是条件概率的一种推断。

### 条件概率 Conditional Probability

是指在 **已知** 事件 B 发生的情况下，此时事件 A 发生的概率，这里用 `P(A|B)` 来表示，此时的表达式可以表示为 `P(B|A)=P(AB)/P(A)` 。

例如，将一枚硬币抛掷两次，其中事件 A 为 "至少一次为正面(H)" ，事件 B 为 "两次掷出同面" ，那么已知事件 A 发生的条件下事件 B 发生的概率。

这里的样本空间为 `S={HH, HT, TH, TT} A={HH, HT, TH} B={HH, TT}` 那么如果事件 A 已经发生，事件 B 发生的概率为 `P(B|A)=[1/4]/[3/4]=1/3` 。

需要注意的是，在这些定义中 A 与 B 之间不一定有因果或者时间序列关系，A 可能会先于 B 发生，也可能相反，也可能二者同时发生；A 可能会导致 B 的发生，也可能相反，也可能二者之间根本就没有因果关系。

如果要考虑一些可能是新的信息的概率条件性可以通过贝叶斯定理实现，也就是说，如果已经确定 B 发生了，那么 A 发生的概率应该是 `P(AB)/P(A)` 。

### 乘法公式

实际上就是上述条件概率的推导，公式为 `P(AB)=P(A|B)P(B)=P(B|A)P(A)` 。

全概率公式、贝叶斯公式推导
https://www.cnblogs.com/ohshit/p/5629581.html
http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_one.html

通过贝叶斯公式，可以明确告知我们如何利用新证据修改已有的看法。

最通俗的讲解
https://www.jianshu.com/p/d9757860c4f8
最经典的故障预测的案例
https://www.matongxue.com/madocs/279.html


概率统计公式大全
https://www.zybuluo.com/catscarf/note/986628
排列和组合详解
https://zhuanlan.zhihu.com/p/41855459
https://seeing-theory.brown.edu/compound-probability/index.html

## 贝叶斯公式

最常见的公式如下：

$$P(A|B) = \frac{P(B|A)P(A)}{P(B)}$$

这个看起来很简单，无非就是条件概率和联合概率公式的组合，其中：

* `P(A)` 是先验概率或者边缘概率，之所以称为 "先验" 是因为不考虑任何与 B 相关的因素，完全独立计算，可以通过大数据统计得到。
* `P(A|B)` 已知 B 发生后 A 发生的概率，称为 A 的后验概率。
* `P(B)` 是先验概率或者边缘概率，也被称为标准化常量 (Normalized Constant)。

按这些术语，Bayes法则可表述为：
后验概率 = (似然度 * 先验概率)/标准化常量 也就是说，后验概率与先验概率和似然度的乘积成正比。
另外，比例Pr(B|A)/Pr(B)也有时被称作标准似然度（standardised likelihood），Bayes法则可表述为：
后验概率 = 标准似然度 * 先验概率
要理解贝叶斯推断，必须先理解贝叶斯定理。后者实际上就是计算"条件概率"的公式。


如果把 P(B) 展开，可以得到如下的公式。

P(A|B) = {P(B|A)P(A)}/{P(B|A)P(A) + P(B|A')P(A')}

其中 `P(A')` 表示非 `A` 的概率，其实后面的公式在实际使用时可能会更多。

## 案例

很多时候示例是最显而易见的讲解方式。

### 案例 #1

一个学校里有 `60%` 男生和 `40%` 女生，女生穿裤子的人数和穿裙子的人数相等，所有男生穿裤子。一个人在远处随机看到了一个穿裤子的学生，那么这个学生是女生的概率是多少？

利用贝叶斯定理，假设事件 A 是看到女生，事件 B 是看到一个穿裤子的学生，那么我们所要计算的是 `P(A|B)`。

* `P(A)` 是忽略其它因素，看到女生的概率，在这里是 `40%`；
* `P(A')` 是忽略其它因素，看到不是女生(也就是看到男生)的概率，在这里是 `60%`；
* `P(B|A)` 是女生穿裤子的概率，在这里是 `50%`；
* `P(B|A')` 是男生穿裤子的概率，在这里是 `100%`；
* `P(B)` 是忽略其它因素，直接考虑学生穿裤子的概率，`P(B) = P(B|A)P(A) + P(B|A')P(A')`，在这里是 `0.5*0.4 + 1*0.6 = 0.8` ；

那么根据贝叶斯公式，可以计算得到，也就是 `P(A|B) = (0.5 * 0.4)/(0.8) = 0.25` 。

### 贝叶斯过滤器

对于垃圾邮件来说，传统使用较多的是关键词，但是很容易误判，2002 年 Paul Graham 提出使用 "贝叶斯推断" 过滤垃圾邮件，取得了很好的效果，据说 1000 封垃圾邮件可以过滤掉 995 封，且没有一个误判。

另外，这种过滤器还具有学习能力，会根据新收到的邮件，不断调整，收到的垃圾邮件越多，它的准确率就越高。

<!--
http://www.ruanyifeng.com/blog/2011/08/bayesian_inference_part_two.html
-->

## 似然函数

### 概率 VS. 似然

在英文的语境中，概率 (Probability) 和 似然 (Likelihood) 的意思基本相同，但是在统计学里面，似然函数和概率函数却是两个不同的概念，只是比较相近或者相关罢了。

例如，对于函数 `P(x|θ)` 而言，其中 `x` 表示具体的数据，`θ` 表示模型的参数：

* 如果 `θ` 已知而 `x` 是变量，这个函数叫做概率函数，描述对于不同的样本点 `x` ，其出现概率是多少。
* 如果 `x` 已知而 `θ` 是变量，这个函数叫做似然函数，描述对于不同的模型参数，出现 `x` 这个样本点的概率是多少。

也就是说，在数理统计中，"概率" 描述了给定模型参数后，描述结果的合理性，而不涉及任何观察到的数据。而 "似然" 则描述了给定了特定观测值后，描述模型参数是否合理。

#### 示例

仍然以抛硬币为例，简单介绍下两者的区别。

这里也就是伯努利实验，其概率分布为 $b(x,n,p)=C_n^xp^xq^{n-x}$

##### 概率

抛一枚均匀的硬币，拋 20 次，问 15 次拋得正面的可能性有多大？ 这里的可能性就是”概率”，均匀的硬币就是给定参数θ=0.5，“拋20次15次正面”是观测值O。求概率P(H=15|θ=0.5)=？的概率。

$b(15, 20, 0.5)={C_20^15}{0.5^15}{0.5^5}=

##### 似然

拋一枚硬币，拋20次，结果15次正面向上，问其为均匀的可能性？ 这里的可能性就是”似然”，“拋20次15次正面”为观测值O为已知，参数θ=?并不知道，求L(θ|H=15)=P(H=15|θ=0.5)的最大化下的θ 值。

### 最大似然估计

### 最大后验概率估计

最大似然、最大后验估计
https://blog.csdn.net/u011508640/article/details/72815981
https://zhuanlan.zhihu.com/p/26614750


{% highlight text %}
{% endhighlight %}
